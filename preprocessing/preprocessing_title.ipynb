{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from fuzzywuzzy import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.path.normpath(os.getcwd() + os.sep + os.pardir) + \"/data/raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.path.join(os.path.normpath(os.getcwd() + os.sep + os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BX-Books.csv',\n",
       " 'BX-NewBooks.csv',\n",
       " 'BX-NewBooksRatings.csv',\n",
       " 'BX-NewBooksUsers.csv',\n",
       " 'BX-Ratings.csv',\n",
       " 'BX-Users.csv']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Bx-Users.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User-ID', 'User-City', 'User-State', 'User-Country', 'User-Age'], dtype='object')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(path + \"/BX-Users.csv\")\n",
    "users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48299, 5)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User-ID          int64\n",
       "User-City       object\n",
       "User-State      object\n",
       "User-Country    object\n",
       "User-Age        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>User-City</th>\n",
       "      <th>User-State</th>\n",
       "      <th>User-Country</th>\n",
       "      <th>User-Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>germantown</td>\n",
       "      <td>tennessee</td>\n",
       "      <td>usa\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>albuquerque</td>\n",
       "      <td>new mexico</td>\n",
       "      <td>usa\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>chesapeake</td>\n",
       "      <td>virginia</td>\n",
       "      <td>usa\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>weston</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>14\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID    User-City   User-State User-Country User-Age\n",
       "0        8      timmins      ontario      canada\"      NaN\n",
       "1        9   germantown    tennessee         usa\"      NaN\n",
       "2       16  albuquerque   new mexico         usa\"      NaN\n",
       "3       17   chesapeake     virginia         usa\"      NaN\n",
       "4       19       weston                       NaN      14\""
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Country Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strip apostrophe and spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>User-City</th>\n",
       "      <th>User-State</th>\n",
       "      <th>User-Country</th>\n",
       "      <th>User-Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>timmins</td>\n",
       "      <td>ontario</td>\n",
       "      <td>canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>germantown</td>\n",
       "      <td>tennessee</td>\n",
       "      <td>usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>albuquerque</td>\n",
       "      <td>new mexico</td>\n",
       "      <td>usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>chesapeake</td>\n",
       "      <td>virginia</td>\n",
       "      <td>usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>weston</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>14\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID    User-City   User-State User-Country User-Age\n",
       "0        8      timmins      ontario       canada      NaN\n",
       "1        9   germantown    tennessee          usa      NaN\n",
       "2       16  albuquerque   new mexico          usa      NaN\n",
       "3       17   chesapeake     virginia          usa      NaN\n",
       "4       19       weston                       NaN      14\""
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['User-Country', 'User-State', 'User-City','User-Age']\n",
    "for column in columns:\n",
    "    users[column] = users[column].apply(lambda x: x.strip().strip('\"') if pd.notnull(x) and isinstance(x, str) else x)\n",
    "users.head()\n",
    "\n",
    "users.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean values supposed to be NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_1 = r'[xX]{2,6}'  # Matches 2 to 6 occurrences of \"X\"\n",
    "pattern_2 = r'\\b(n/a)\\b' # Matches n/a \n",
    "pattern_3 = r'^\\s$|^$' #matches whitespace entries\n",
    "pattern_4 = r'-' # matches hyphen\n",
    "\n",
    "\n",
    "# Replace matching values with np.nan\n",
    "for column in ['User-Country', 'User-State', 'User-City']:\n",
    "    # Replace matching values with np.nan using the respective pattern\n",
    "    users[column] = users[column].replace(pattern_1, np.nan, regex=True)\n",
    "    users[column] = users[column].replace(pattern_2, np.nan, regex =True)\n",
    "    users[column] = users[column].replace(pattern_3, np.nan, regex=True)\n",
    "    users[column] = users[column].replace(pattern_4, np.nan, regex=True)\n",
    "\n",
    "  \n",
    "# Fill remaining NaN values with np.nan\n",
    "users.fillna(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Abbreviated names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary of abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviation_dict = {\n",
    "    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#States.\n",
    "    \"AK\": \"Alaska\",\n",
    "    \"AL\": \"Alabama\",\n",
    "    \"AR\": \"Arkansas\",\n",
    "    \"AZ\": \"Arizona\",\n",
    "    \"CA\": \"California\",\n",
    "    \"CO\": \"Colorado\",\n",
    "    \"CT\": \"Connecticut\",\n",
    "    \"DE\": \"Delaware\",\n",
    "    \"FL\": \"Florida\",\n",
    "    \"GA\": \"Georgia\",\n",
    "    \"HI\": \"Hawaii\",\n",
    "    \"IA\": \"Iowa\",\n",
    "    \"ID\": \"Idaho\",\n",
    "    \"IL\": \"Illinois\",\n",
    "    \"IN\": \"Indiana\",\n",
    "    \"KS\": \"Kansas\",\n",
    "    \"KY\": \"Kentucky\",\n",
    "    \"LA\": \"Louisiana\",\n",
    "    \"MA\": \"Massachusetts\",\n",
    "    \"MD\": \"Maryland\",\n",
    "    \"ME\": \"Maine\",\n",
    "    \"MI\": \"Michigan\",\n",
    "    \"MN\": \"Minnesota\",\n",
    "    \"MO\": \"Missouri\",\n",
    "    \"MS\": \"Mississippi\",\n",
    "    \"MT\": \"Montana\",\n",
    "    \"NC\": \"North Carolina\",\n",
    "    \"ND\": \"North Dakota\",\n",
    "    \"NE\": \"Nebraska\",\n",
    "    \"NH\": \"New Hampshire\",\n",
    "    \"NJ\": \"New Jersey\",\n",
    "    \"NM\": \"New Mexico\",\n",
    "    \"NV\": \"Nevada\",\n",
    "    \"NY\": \"New York\",\n",
    "    \"OH\": \"Ohio\",\n",
    "    \"OK\": \"Oklahoma\",\n",
    "    \"OR\": \"Oregon\",\n",
    "    \"PA\": \"Pennsylvania\",\n",
    "    \"RI\": \"Rhode Island\",\n",
    "    \"SC\": \"South Carolina\",\n",
    "    \"SD\": \"South Dakota\",\n",
    "    \"TN\": \"Tennessee\",\n",
    "    \"TX\": \"Texas\",\n",
    "    \"UT\": \"Utah\",\n",
    "    \"VA\": \"Virginia\",\n",
    "    \"VT\": \"Vermont\",\n",
    "    \"WA\": \"Washington\",\n",
    "    \"WI\": \"Wisconsin\",\n",
    "    \"WV\": \"West Virginia\",\n",
    "    \"WY\": \"Wyoming\",\n",
    "    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#Federal_district.\n",
    "    \"DC\": \"District of Columbia\",\n",
    "    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#Inhabited_territories.\n",
    "    \"AS\": \"American Samoa\",\n",
    "    \"GU\": \"Guam GU\",\n",
    "    \"MP\": \"Northern Mariana Islands\",\n",
    "    \"PR\": \"Puerto Rico PR\",\n",
    "    \"VI\": \"U.S. Virgin Islands\",\n",
    "    'sg': 'singapore',\n",
    "    'jax': \"Jacksonville\",\n",
    "    'nyc' : \"New York City\",\n",
    "    'ny' : 'New York',\n",
    "    'la':'Las Vegas',\n",
    "    'wi': \"Wisconsin\",\n",
    "    'sj' : 'San Jose',\n",
    "    'pdx':'portland',\n",
    "    'atl' : 'atlanta',\n",
    "    'rtr' : 'Remedios T. Romualdez',\n",
    "    'phx' : 'phoenix',\n",
    "    'hyd':'Hyderabad',\n",
    "    'bcn': 'Barcelona',\n",
    "    'ala':'alabama',\n",
    "    'rr':'round rock', \n",
    "    'dc': \"washington d.c\",\n",
    "    'apo': 'apopka',\n",
    "    'kdh':'kill devil hills',\n",
    "    'yvr': 'vancouver',\n",
    "    'okc' : 'oklahoma city',\n",
    "    'abq' :'albuquerque',\n",
    "    'pve': 'palos verdes estates' ,\n",
    "    'dfb' :'deerfield beach',\n",
    "    'pj' : 'petaling Jaya',\n",
    "    'van' : 'vancouver',\n",
    "    'rsm' : 'Rancho Santa Margarita',\n",
    "    'rvc' : \" Rockville centre\",\n",
    "    'srq' : 'Sarasota',\n",
    "    'br' : 'baton rouge',\n",
    "    'kl' : \"Kuala Lumpur\",\n",
    "    'kc' :'kansas city',\n",
    "    'abc' : \"alphabet city\",\n",
    "    'sf' : \"San Francisco\",\n",
    "    'slc' : 'salt lake city',\n",
    "    'wbl' : 'white bear lake', \n",
    "    'rtp' : 'research triangle park', \n",
    "    'li' : 'long island', \n",
    "    'hhi' : 'Hilton head island',\n",
    "    \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_dict(data):\n",
    "  \"\"\"Creates a new dictionary with lowercase keys.\"\"\"\n",
    "  return {key.lower(): value for key, value in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ak': 'Alaska', 'al': 'Alabama', 'ar': 'Arkansas', 'az': 'Arizona', 'ca': 'California', 'co': 'Colorado', 'ct': 'Connecticut', 'de': 'Delaware', 'fl': 'Florida', 'ga': 'Georgia', 'hi': 'Hawaii', 'ia': 'Iowa', 'id': 'Idaho', 'il': 'Illinois', 'in': 'Indiana', 'ks': 'Kansas', 'ky': 'Kentucky', 'la': 'Las Vegas', 'ma': 'Massachusetts', 'md': 'Maryland', 'me': 'Maine', 'mi': 'Michigan', 'mn': 'Minnesota', 'mo': 'Missouri', 'ms': 'Mississippi', 'mt': 'Montana', 'nc': 'North Carolina', 'nd': 'North Dakota', 'ne': 'Nebraska', 'nh': 'New Hampshire', 'nj': 'New Jersey', 'nm': 'New Mexico', 'nv': 'Nevada', 'ny': 'New York', 'oh': 'Ohio', 'ok': 'Oklahoma', 'or': 'Oregon', 'pa': 'Pennsylvania', 'ri': 'Rhode Island', 'sc': 'South Carolina', 'sd': 'South Dakota', 'tn': 'Tennessee', 'tx': 'Texas', 'ut': 'Utah', 'va': 'Virginia', 'vt': 'Vermont', 'wa': 'Washington', 'wi': 'Wisconsin', 'wv': 'West Virginia', 'wy': 'Wyoming', 'dc': 'washington d.c', 'as': 'American Samoa', 'gu': 'Guam GU', 'mp': 'Northern Mariana Islands', 'pr': 'Puerto Rico PR', 'vi': 'U.S. Virgin Islands', 'sg': 'singapore', 'jax': 'Jacksonville', 'nyc': 'New York City', 'sj': 'San Jose', 'pdx': 'portland', 'atl': 'atlanta', 'rtr': 'Remedios T. Romualdez', 'phx': 'phoenix', 'hyd': 'Hyderabad', 'bcn': 'Barcelona', 'ala': 'alabama', 'rr': 'round rock', 'apo': 'apopka', 'kdh': 'kill devil hills', 'yvr': 'vancouver', 'okc': 'oklahoma city', 'abq': 'albuquerque', 'pve': 'palos verdes estates', 'dfb': 'deerfield beach', 'pj': 'petaling Jaya', 'van': 'vancouver', 'rsm': 'Rancho Santa Margarita', 'rvc': ' Rockville centre', 'srq': 'Sarasota', 'br': 'baton rouge', 'kl': 'Kuala Lumpur', 'kc': 'kansas city', 'abc': 'alphabet city', 'sf': 'San Francisco', 'slc': 'salt lake city', 'wbl': 'white bear lake', 'rtp': 'research triangle park', 'li': 'long island', 'hhi': 'Hilton head island'}\n"
     ]
    }
   ],
   "source": [
    "lowercase_keys = lowercase_dict(abbreviation_dict)\n",
    "print(lowercase_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['User-City','User-State']\n",
    "for index, row in users.iterrows():\n",
    "    for col in cols:            \n",
    "        if row[col] in abbreviation_dict:\n",
    "            users.at[index, col] = abbreviation_dict[row['col']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in empty states/countries via data base from : \n",
    "\n",
    "https://simplemaps.com/data/us-cities\n",
    "\n",
    "https://simplemaps.com/data/world-cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_path = os.path.join(os.path.normpath(os.getcwd() + os.sep + os.pardir) + \"/data/cities\")\n",
    "cities = pd.read_csv(cities_path + \"/worldcities.csv\")\n",
    "us_cities = pd.read_csv(cities_path + \"/uscities.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Relevant collumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities[['city_ascii','country', 'admin_name']]\n",
    "cities = cities[['city_ascii', 'country', 'admin_name']].rename(columns={'admin_name': 'state_name'})\n",
    "filtered = cities[cities['country'] != 'United States']\n",
    "print(cities.shape)\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_cities = us_cities[['city_ascii','state_name']]\n",
    "us_cities['country'] = 'usa'\n",
    "print(us_cities.shape)\n",
    "us_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.concat([cities,us_cities], axis = 0)\n",
    "cities = cities[['city_ascii', 'country', 'state_name']].rename(columns={'state_name': 'states'})\n",
    "\n",
    "print(cities.shape)\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Case folding\n",
    "\n",
    "I also altered the format for the database i found online to match our situation better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities['city_ascii'] = cities['city_ascii'].str.lower()\n",
    "cities['country'] = cities['country'].str.lower()\n",
    "cities['states'] = cities['states'].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing naming deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities['country'] = cities['country'].replace('korea, south', 'south korea', regex=True)\n",
    "cities['country'] = cities['country'].replace('united states', 'usa', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing corrosponding states and country from cities\n",
    "\n",
    "We are able to tell what state and country it is from the city, but we can't neccesarily tell the city from the country. <br>\n",
    "So we will fuzzy match the cities where the row has a city name but not a state or country.<br> We will then find the corrosponding state and city in the cities database and fill those in.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fredericton\n"
     ]
    }
   ],
   "source": [
    "def fuzzy_match(input_string, choices):\n",
    "    # Use process.extractOne to find the best match\n",
    "    best_match, score = process.extractOne(input_string, choices)\n",
    "    return best_match, score\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cities_list \u001b[38;5;241m=\u001b[39m cities[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity_ascii\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m      2\u001b[0m cities_list\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cities' is not defined"
     ]
    }
   ],
   "source": [
    "cities_list = cities['city_ascii'].to_list()\n",
    "cities_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values into cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in users.iterrows():\n",
    "    if (not pd.isnull(row['User-City'])) and (pd.isnull(row['User-State']) or pd.isnull(row['User-Country'])):\n",
    "        city_to_find =fuzzy_match(row['User-City'],cities_list)[0]\n",
    "        print(city_to_find)\n",
    "        city_mask = cities[cities['city_ascii'] == city_to_find]\n",
    "        if not city_mask.empty:\n",
    "            state = city_mask['states'].iloc[0]\n",
    "            country = city_mask['country'].iloc[0]\n",
    "            users.loc[index, 'User-State'] = state\n",
    "            users.loc[index, 'User-Country'] = country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_age = users.dropna(subset=['User-Age'])\n",
    "valid_age['User-Age'] = pd.to_numeric(valid_age['User-Age'], errors='coerce')\n",
    "valid_age.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age_by_country = valid_age.groupby('User-Country')['User-Age'].mean()\n",
    "overall_mean_age = valid_age['User-Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation for Nan and setting outliers as mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in users.iterrows():\n",
    "    if pd.isna(row['User-Age']) or row['User-Age'] > 90 or row['User-Age'] < 0:\n",
    "        country = row['User-Country']\n",
    "        if country in mean_age_by_country:\n",
    "            users.at[index, 'User-Age'] = mean_age_by_country[country]\n",
    "        else:\n",
    "            users.at[index, 'User-Age'] = overall_mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Bx-NewBooksUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users = pd.read_csv(path + \"/BX-NewBooksUsers.csv\")\n",
    "new_users.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing should be Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_1 = r'[xX]{2,6}'  # Matches 2 to 6 occurrences of \"X\"\n",
    "pattern_2 = r'\\b(n/a)\\b' # Matches n/a \n",
    "pattern_3 = r'^\\s$|^$' #matches whitespace entries\n",
    "\n",
    "# Replace matching values with np.nan\n",
    "for column in ['User-Country', 'User-State', 'User-City']:\n",
    "    # Replace matching values with np.nan using the respective pattern\n",
    "    new_users[column] = new_users[column].replace(pattern_1, np.nan, regex=True)\n",
    "    new_users[column] = new_users[column].replace(pattern_2, np.nan)\n",
    "    new_users[column] = new_users[column].replace(pattern_3, np.nan, regex=True)\n",
    "\n",
    "# Fill remaining NaN values with np.nan\n",
    "new_users.fillna(np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strip apostophe and spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['User-Country', 'User-State', 'User-City','User-Age']\n",
    "for column in columns:\n",
    "    new_users[column] = new_users[column].apply(lambda x: x.strip().strip('\"') if pd.notnull(x) and isinstance(x, str) else x)\n",
    "new_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Abreviations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['User-City','User-State']\n",
    "for index, row in users.iterrows():\n",
    "    for col in cols:            \n",
    "        if row[col] in abbreviation_dict:\n",
    "            users.at[index, col] = abbreviation_dict[row['col']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuzzy Match and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in new_users.iterrows():\n",
    "    if (not pd.isnull(row['User-City'])) and (pd.isnull(row['User-State']) or pd.isnull(row['User-Country'])):\n",
    "        city_to_find =fuzzy_match(row['User-City'],cities_list)[0]\n",
    "        print(city_to_find)\n",
    "        city_mask = cities[cities['city_ascii'] == city_to_find]\n",
    "        if not city_mask.empty:\n",
    "            state = city_mask['states'].iloc[0]\n",
    "            country = city_mask['country'].iloc[0]\n",
    "            new_users.loc[index, 'User-State'] = state\n",
    "            new_users.loc[index, 'User-Country'] = country\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We impute Nan age with the country mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_age = new_users.dropna(subset=['User-Age'])\n",
    "valid_age['User-Age'] = pd.to_numeric(valid_age['User-Age'], errors='coerce')\n",
    "valid_age.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age_by_country = valid_age.groupby('User-Country')['User-Age'].mean()\n",
    "overall_mean_age = valid_age['User-Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation and also fixing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in new_users.iterrows():\n",
    "    if pd.isna(row['User-Age']) or row['User-Age'] > 90 or row['User-Age'] < 0:\n",
    "        country = row['User-Country']\n",
    "        if country in mean_age_by_country:\n",
    "            new_users.at[index, 'User-Age'] = mean_age_by_country[country]\n",
    "        else:\n",
    "            new_users.at[index, 'User-Age'] = overall_mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv('Bx-Cleaned-Users')\n",
    "new_users.to_csv('Bx-Cleaned-NewBooksUsers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
